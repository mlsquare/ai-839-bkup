[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "AI-839",
    "section": "",
    "text": "Welcome\nHello Students of AI 839.\nSee the course page for recent information on Lectures, Homeworks, Projects, etc..",
    "crumbs": [
      "Welcome"
    ]
  },
  {
    "objectID": "preface.html",
    "href": "preface.html",
    "title": "Preface",
    "section": "",
    "text": "Why MLOps?\nFirst and foremost, let us swallow the bitter pill - ML is just a piece of technology like any other to solve a business problem for which somebody needs to pay for. It means that unless people use it and pay for this technology (models), no matter how sophisticated and cool do they sound, they byte the dust like most ML initiatives do.\nNot just that - industry needs and loves determinism, accountability and reliability, which is the antithesis on which ML lives and thrives. MLOps is about addressing this inherent design challenge using a combination of tools and processes. Without which one has to appeal to luck to achieve the desirable. And we know from experience that luck favors the prepared.\nThis collection of notes on MLOps is about that preparation to manage the entire life cycle of an ML product, holistically and comprehensively. That is, for example, the ML system must be performant, explainable, reliable, fair and transparent, responsive and responsible, controllable, cost effective, collaborative, and many others, all which will discussed in detail later in the course.\n\n\nWhy A course on MLOps?\n\nUnderestimation of Technical Debt\n\nDeveloping ML systems involves significant technical complexities that are often underestimated, chiefly arising out of model-centric pedagogy.\nUnlike traditional software development, ML systems require continuous monitoring and iteration of the situated environment\n\nFundamental Differences from Traditional Software Development\n\nTraditional software development assumes a stable environment and known requirements.\nML systems, however, must adapt to changing environments and data, making it impossible to assume a perfect product at deployment.\n\nUncertain Data Environment\n\nAI systems inherently make mistakes and must be designed to handle continuous change and evolution.\nA good model in the lab does not guarantee performance in production, necessitating robust MLOps practices.\nThe deployment and monitoring of ML systems differ fundamentally from traditional software.\nContinuous monitoring and iteration are essential for maintaining model performance and relevance.\n\nOperationalizing ML\n\nOperationalizing ML is crucial for deriving value from AI systems, aligning them with business objectives and real-world applications. This can be a non-trivial activity, if not impossible in some cases.\nThis mindset is essential for understanding the practical aspects of ML deployment and maintenance.\n\n\nA course on MLOps exposes the developer or system designer to this varying challenges in the life cycle of ML (which is perpetual). This is entirely different from how one could solve an ML problem in academic settings where, more often than not, model novelty is incentivized over utility.\n\n\nWhy THIS course on MLOps?\nThere are many great resources available on the web in terms of books, blogs, courses, and tool documentation. Why yet another one? A legit question.\nAt a philosophical level - there are two objectives:\n\nFight the SOTA syndrome:\nLet me explain.\nThanks to chatGPT, it all seems to be about LLMs - building new models, spinning new shiny applications built around those LLMs both open and closed included. These new shiny objects exacerbated an already sick situation - a situation where building models (model.train) showing 0.01% (or even less) increase in accuracy is chased and cherished – all about State-of-the-Art (SOTA).\nWhile we must work hard and smart to move the needle, and it might be satisfying and fulfilling intellectually – unfortunately, it (chasing SOTA) is neither necessary nor sufficient to build reliable systems consisting of at least one ML component. There is lot more one has to consider in building and managing such systems.\nPrioritizes utility over novelty:\nAdmittedly, it is a boring job to be done. However, contrary to the prejudice, in the due course, you will learn that, indeed, solving for utility and overcoming the challenges along the way, is a rewarding journey in itself. Give no cult status to SOTA.\n\nMore concretely, there are some limitations of current MLOps Resources - they are notably:\n\nPractitioner-Focused Literature\n\nMost current MLOps books and resources are aimed at practitioners.\nThese resources focus heavily on tools and practices without structured assessment components.\nOften they anchor on specific framework/tool set.\n\nNeed for Academic Assessment\n\nIn academia, assessments are a crucial part of the learning process.\nThis material should not only teach concepts but also include tests to evaluate understanding.\nTesting is fundamental to learning and ensures that students grasp and can apply MLOps concepts effectively.\n\nComprehensive Curriculum\n\nThe course should cover not only MLOps but also ML system design and the operationalization of models.\nIntegrating these elements ensures a holistic understanding of both the development and deployment aspects of ML projects.\n\n\nSo the chief difference is - most of the resources are meant for practitioners. But this set of notes is meant both for students who can learn the tools and processes, and apply them and also for practitioners (who can learn the principles). But some of the challenges are more systemic and pervasive outlined below:\n\nVariability in MLOps Practices\n\nMLOps processes and practices vary significantly between individuals and organizations.\nUnlike DevOps in the software industry, which has become a mainstream discipline with standardized practices, MLOps is still relatively young.\n\nAbsence of Standard Vocabulary\n\nThere is no non-denominational vocabulary in MLOps, leading to inconsistencies in terminology and practices.\nStandardizing terminology and processes is crucial for effective communication and collaboration within and between organizations.\n\nKnowledge Diffusion and Skill Gap\n\nTraditional academic institutions typically propagate certain ideas and knowledge that get absorbed and amplified in the industry. But the reverse diffusion is often delayed.\nThere can be a lag between what academia offers and what the industry needs, especially in rapidly evolving fields like ML.\nset of templates (of code bases and also of materialized principles) that anybody can use in the Industry which improves the overall employee productivity of the employee\n\nNo Institutionalized MLOps Thinking\n\nInstitutionalizing MLOps in academic programs ensures that students are trained in industry-relevant skills from the start.\nThis approach can help standardize the quality and relevance of ML education, making graduates industry-ready.\nIntroduce a conceptual framework of models, actors and actions involved and a vocabulary to describe the complex ML dev cycle\nProvide a holistic view of ML - going beyond chasing performance metrics\npractice the principle theory-with-code and code-with-theory so that every principle is practicable, and every practice has a principle\ndevelop good (conceptual) models and principles which industry can adopt\n\n\n\n\nBenefits for Students\n\nIndustry Readiness\n\nInstead of learning these skills during internships or on the job, students will acquire them as part of their academic experience.\nThis prepares students to be industry-ready upon graduation, reducing the training burden on employers.\n\nHolistic Approach to Machine Learning\n\nThe course promotes a holistic view of ML, integrating model-centric and data-centric approaches.\nStudents will learn to consider all aspects of ML, including data quality, model robustness, and system integration.\n\nResponsible AI\n\nThe curriculum will cover aspects of responsible AI, ensuring that students are aware of ethical considerations and best practices in AI deployment.\nThis includes understanding biases, fairness, transparency, and accountability in ML models.\n\nComprehensive Skill Set\n\nStudents will gain a broad set of skills, from ML system design to operationalizing models.\nThis comprehensive skill set ensures that graduates are well-prepared to handle the full ML lifecycle in professional settings.\n\n\n\n\nBenefits for Academic Institutions\n\nPioneering Course Offering in India\n\nThis course is likely the first of its kind being offered in India, positioning the institution as a leader in ML education.\nBuilding on existing curricula such as Introduction to Machine Learning, Deep Learning, and Introduction to DevOps.\n\nIndustry-Relevant Education\n\nBy incorporating industry perspectives, including guest lectures and hands-on projects, the course aligns academic training with real-world needs.\nFold industry needs into the curriculum: students often gain experience in developing models and ML system design through internships, and this is transactional by design. This experiential knowledge has to be scaled with backward integration into the curriculum\nThis practitioner-oriented approach ensures students gain practical experience.\n\nEnhanced Employability\n\nAcademic institutions benefit by producing graduates who are immediately employable.\nStrong industry partnerships and placement opportunities can be developed, enhancing the institution’s reputation and appeal to prospective students.\nEquip students with essential skills: in ML lifecycle management, including deployment, monitoring, and automation\nPrepares students for roles such as ML engineer, MLOps engineer, and data scientist with operations expertise\nFamiliarize students with MLOps tools and platforms (e.g., Kubeflow, MLflow, TFX).\nEnhance the overall learning experience: By providing practical, hands-on experience with industry-relevant tools and practices\n\nCater to new market: As there is growing demand for MLOps skills in the industry due to the increasing adoption of AI and ML technologies. Organizations are looking for professionals who can manage the end-to-end ML lifecycle\n\n\n\nBenefits for Industry\n\nReducing Ad-Hoc Practices\n\nThe course aims to reduce the ad-hoc nature of MLOps practices and bring consistency to tooling choices.\nSimilar to how standardized practices in software development (e.g., Java build tools, POM) have streamlined processes, this course seeks to standardize MLOps practices.\n\nBuilding a Talent Pool\n\nThe industry will benefit from a pool of talent that is job-ready, reducing the onboarding time and training costs.\nGraduates will be proficient in MLOps practices, making them productive and profitable employees from the start.\n\nConceptual Frameworks for MLOps\n\nWhile the tools and techniques for implementing MLOps may vary, the course will provide students with robust frameworks and methodologies.\nThese frameworks will help students understand and apply MLOps principles in various contexts and adapt to new technologies as they emerge.\n\n\n\nThis course aims to introduce concepts that will stand the test of time, despite the rapid evolution of tools and techniques.\n\nBy focusing on foundational principles, the course provides a framework for thinking about MLOps that remains relevant as the field evolves.\n\n\n\nConsistency and Knowledge Transfer\n\nStandardized MLOps training ensures that professionals can move between projects with ease, facilitating better knowledge transfer and collaboration.\nThis reduces the time and effort needed to get new hires up to speed on MLOps practices within the organization.\n\n\n\n\nStyle\nContent will be presented in the form of take-away points, rather than main take-aways embedded in long winding paragraphs. Nuances etc will be added in the due course of time or video recordings will be made available.\n\n\nDisclaimer\nThis course is by no means a replacement of any other resources available. Hopefully, the content and views presented complement the current practice of MLOps, readers and students benefit from it.\nopenly,\nThe Saddle Point",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "Introduction",
    "section": "",
    "text": "Introduction to the the book. Not preface",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "courses-fullstack-semester.html",
    "href": "courses-fullstack-semester.html",
    "title": "Full Semester Course",
    "section": "",
    "text": "Below is an organization of the content to offer a 14 week full semester with 4 contact hours. It can be roughly divided into 3 parts.\n\nOverview\nPrereqs\n\nExposure and skill in data handling, building models in Python, PyTorch\nExposure and skill in developing code using Python, Git, IDEs like VS Code\nA foundation course in Machine Learning, Deep Learning, Data Modeling, working with (Big) Data\n\nPart-1: Essentials\n\nTopics\n\nbasic principles and MLOps with Open Source Software\ntwo assignments\n\nLearning Outcomes: students will be able to\n\ndeploy models with logging, documentation, unit tests, and APIs\nunderstand a conceptual framework to understand MLOps\n\n\nPart-2: Full Stack MLOps\n\nTopics\n\nholistic understanding of ML development, beyond chasing typical performance metrics\none assignment, one mini project and a midterm\n\nLearning Outcomes: students will be able to\n\ndeploy models, observe their performance, make improvements, redeploy them.\n\nensure that the ML pipeline is reproducible.\nincorporate principles from Responsible AI and build ML systems which can consist of many models and tools.\n\n\nPart-3: Application\n\nTopics\n\npractice, Cloud solutions\ncapstone project and presentations\ninvited lectures from Industry\n\nLearning Outcomes: students will be able to\n\nframe, discover, develop, deploy, monitor, improve, re-deploy and maintain an ML Application\napproach the problem holistically, optimize RoI\n\n\nGrading:\n\n10%: Scribe lecture notes\n30%: Three assignments, each 10%\n15%: Midterm mini project\n20%: In-class midterm MCQs, FIBs, Data Interpretation\n25%: Capstone project\n\n\n\nSuggested Schedule (WIP)\n\n\nPart-1: Essentials\n\n\n\n\n\n\nWeek\nTopics\n\n\n\n\n01\nDiscovery  1. Course Objectives and ML Recap  2. ML Lifecycle, Fullstack ML Infrastructure  3. DAGs, Software 1.0 vs 2.0, Tool Ecosystem, Project Setup  4. Project Canvas & Human-centered Design\n\n\n \nAssignment-01: Build a model that is well documented, modular, testable and functional\n\n\n02\nData Engineering  1. Design Patterns & Considerations, Data Models  2. ETL (with Flyte/dbt) and Feature Store (Chronon)  3. Data Versioning with DVC/Kedro and Logging  4. Feature Engineering with TFX/DFL/Encodings\n\n\n \nNo Assignment:\n\n\n03\nModel Development & Experimentation  1. Design Patterns & Considerations  2. Developing and Managing multiple models (with Hydra)  3. Model versioning with MLFlow  4.DoEs, Experiment tracking with WandB\n\n\n \nAssignment-02: Build: run multiple experiments, benchmark with a baseline, pick a top performing model\n\n\n04\nDeploy & Serve  1. Design Patterns & Considerations Deploy with Docker  2. Model Serving (FastAPI, Flask)  3. Build a demo with Gradio\n\n\n \nNo Assignment:\n\n\n05\nEvaluation & CI/CD 1. Design Patterns & Considerations  2. CI/CD with Github Actions  3. Model Evaluation and benchmarking  4. A/B Testing\n\n\n \nAssignment-03: Build: test multiple models, and based on performance, roll out the best performing model for all users\n\n\n\n\nPart-2: Fullstack MLOps\n\n\n\n\n\n\nWeek\nTopics\n\n\n\n\n06\nPerformance Scaling, Continuous Testing  1. Design Patterns & Considerations  2. Scaling training and serving with MetaFlow/ TrueFoundry  3. Continuous Testing  4. RoI on experiments (no free lunch)\n\n\n \nNo Assignment:\n\n\n07\nObservibility, Reproducibility  1. Design Patterns & Considerations  2. Statistical tests for Model Drift, Data Drift  3. Monitoring drift with Alibi  4. R4 framework\n\n\n \nMidterm mini project: Build  1. ML pipeline that is reproducible, and  2. Implement “Replace” strategy where certain predictions were wrong, remove those data points, and redeploy the model\n\n\n08\nTrustworthy ML  1. Design Patterns & Considerations  2. Conformalization for Statistical Guarantees OOD  3. Human-in-the-Loop, Abstention, System of Models\n\n\n \nNo Assignment\n\n\n09\nResponsible ML  1. Design Patterns & Considerations  2. Fairness, Safety, Alignment  3. Fairness with IBM 360\n\n\n \nNo Assignment:\n\n\n10\nData Centric AI and Pipeline Debugging  1. Automated Debug of Data and Pretrained Models  2. Human side of AI  3. Data Cards, Model Cards, Modeling Cards\n\n\n \nMidterm: in-class\n\n\n\n\nPart-3: Practice\n\n\n\n\n\n\nWeek\nTopics\n\n\n\n\n11\nCase Study:  Putting It Together using OSS tools  Develop a RAG Chatbot using Mistral-7B\n\n\n12\nMLOps on Cloud Platforms  [Databricks, Google Vertex, AWS SageMaker, MS Azure, TrueFOundry, OuterBounds]  1. ETL and Feature Store  2. Train, Deploy, Monitor  3. A/B testing  4. CI/CD under drift strategy where certain predictions were wrong, remove those data points, and redeploy the model\n\n\n13\nPractitioner Talks and Ask Me Anything Sessions  1. Healthcare  2. Retail/ e-commerce  3. Logistics/ Supply Chain  4. Agriculture\n\n\n14\nProject Presentations by Teams\n\n\n\n\nopenly,\nThe Saddle Point",
    "crumbs": [
      "courses.qmd",
      "Full Semester Course"
    ]
  },
  {
    "objectID": "index.html#announcements",
    "href": "index.html#announcements",
    "title": "AI-839",
    "section": "Announcements",
    "text": "Announcements\n\n[01-August-2023] Course website up",
    "crumbs": [
      "Welcome"
    ]
  },
  {
    "objectID": "course.html",
    "href": "course.html",
    "title": "Course",
    "section": "",
    "text": "Syllabus & Schedule",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Course</span>"
    ]
  },
  {
    "objectID": "projects.html",
    "href": "projects.html",
    "title": "Projects",
    "section": "",
    "text": "Tabular Models\ntbd\n\n\nNL2SQL\ntbd",
    "crumbs": [
      "Projects"
    ]
  },
  {
    "objectID": "index.html#overview",
    "href": "index.html#overview",
    "title": "AI-839",
    "section": "Overview",
    "text": "Overview\nPrereqs\n\nExposure and skill in data handling, building models in Python, PyTorch\nExposure and skill in developing code using Python, Git, IDEs like VS Code\nA foundation course in Machine Learning, Deep Learning, Data Modeling, working with (Big) Data\n\nPart-1: Essentials\n\nTopics\n\nbasic principles and MLOps with Open Source Software\nthree assignments\n\nLearning Outcomes: students will be able to\n\ndeploy models with logging, documentation, unit tests, and APIs\nunderstand a conceptual framework to approach MLOps holistically\n\n\nPart-2: Full Stack MLOps\n\nTopics\n\nholistic understanding of ML development, beyond chasing typical performance metrics\none assignment, one mini project and a midterm\n\nLearning Outcomes: students will be able to\n\ndeploy models, observe their performance, make improvements, redeploy them.\n\nensure that the ML pipeline is reproducible.\nincorporate principles from Responsible AI and build ML systems which can consist of many models and tools.\n\n\nPart-3: Intro to LLMOps & Application\n\nTopics\n\npractice, cloud solutions\ncapstone project and presentations\ninvited lectures from Industry\n\nLearning Outcomes: students will be able to\n\nframe, discover, develop, deploy, monitor, improve, re-deploy and maintain an ML Application\napproach the problem holistically, optimize RoI",
    "crumbs": [
      "Welcome"
    ]
  },
  {
    "objectID": "index.html#grading",
    "href": "index.html#grading",
    "title": "AI-839",
    "section": "Grading",
    "text": "Grading\n\n10%: Scribe lecture notes\n30%: Four assignments\n15%: Midterm mini project\n20%: In-class midterm\n25%: Capstone project",
    "crumbs": [
      "Welcome"
    ]
  },
  {
    "objectID": "index.html#policies",
    "href": "index.html#policies",
    "title": "AI-839",
    "section": "Policies",
    "text": "Policies\nLate Submissions All deadlines are due at on the date and time indicated on the course page. The penalties for late submission are as follows:\n\nless than a day : 25% penalty\nmore than a day, less than two days: 50% penalty\n75% penalty otherwise.\n\nMake-up Exam/Submission Policy\nAs per institute policy\nCitation Policy for Papers (if applicable)\nAlways mention the source, give full attribution and credits to citations, and as per institute policy\nAcademic Dishonesty/Plagiarism\nAs per institute policy\nAccommodation of Divyangs\nAs per institute policy\nSoma S Dhavala\nCourse Instructor",
    "crumbs": [
      "Welcome"
    ]
  },
  {
    "objectID": "course.html#references",
    "href": "course.html#references",
    "title": "Course",
    "section": "References",
    "text": "References\n\n\n[1] A.\nBurkov, ML engineering. LeanPub, 2019. Available: https://www.mlebook.com/wiki/doku.php\n\n\n[2] V.\nTuulos, Effective data science infrastructure. Manning, 2023.\nAvailable: https://www.manning.com/books/effective-data-science-infrastructure\n\n\n[3] C.\nHuyen, ML system design. O’Rielly, 2023. Available: https://www.oreilly.com/library/view/designing-machine-learning/9781098107956/\n\n\n[4] C.\nHuyen, “CS329S @ stanford - lecture 1: ML systems in\nproduction,” [Online]. Available: https://docs.google.com/document/d/1C3dlLmFdYHJmACVkz99lSTUPF4XQbWb_Ah7mPE12Igo/edit#heading=h.a8w2b79yy875\n\n\n[5] G.\nMohandas, “MLOps course.” [Online]. Available: https://github.com/GokuMohandas/mlops-course",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Course</span>"
    ]
  },
  {
    "objectID": "course.html#overview",
    "href": "course.html#overview",
    "title": "Course",
    "section": "Overview",
    "text": "Overview\nPrereqs\n\nExposure and skill in data handling, building models in Python, PyTorch\nExposure and skill in developing code using Python, Git, IDEs like VS Code\nA foundation course in Machine Learning, Deep Learning, Data Modeling, working with (Big) Data\n\nPart-1: Essentials\n\nTopics\n\nbasic principles and MLOps with Open Source Software\nthree assignments\n\nLearning Outcomes: students will be able to\n\ndeploy models with logging, documentation, unit tests, and APIs\nunderstand a conceptual framework to approach MLOps holistically\n\n\nPart-2: Full Stack MLOps\n\nTopics\n\nholistic understanding of ML development, beyond chasing typical performance metrics\none assignment, one mini project and a midterm\n\nLearning Outcomes: students will be able to\n\ndeploy models, observe their performance, make improvements, redeploy them.\n\nensure that the ML pipeline is reproducible.\nincorporate principles from Responsible AI and build ML systems which can consist of many models and tools.\n\n\nPart-3: Intro to LLMOps & Application\n\nTopics\n\npractice, cloud solutions\ncapstone project and presentations\ninvited lectures from Industry\n\nLearning Outcomes: students will be able to\n\nframe, discover, develop, deploy, monitor, improve, re-deploy and maintain an ML Application\napproach the problem holistically, optimize RoI\n\n\n\nReferences\n\n\n[1] C.\nHuyen, ML system design. O’Rielly, 2023. Available: https://www.oreilly.com/library/view/designing-machine-learning/9781098107956/\n\n\n[2] A.\nBurkov, ML engineering. LeanPub, 2019. Available: https://www.mlebook.com/wiki/doku.php\n\n\n[3] V.\nTuulos, Effective data science infrastructure. Manning, 2023.\nAvailable: https://www.manning.com/books/effective-data-science-infrastructure\n\n\n[4] G.\nMohandas, “MLOps course.” [Online]. Available: https://github.com/GokuMohandas/mlops-course\n\n\n[5] C.\nHuyen, “CS329S @ stanford - lecture 1: ML systems in\nproduction,” [Online]. Available: https://docs.google.com/document/d/1C3dlLmFdYHJmACVkz99lSTUPF4XQbWb_Ah7mPE12Igo/edit#heading=h.a8w2b79yy875",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Course</span>"
    ]
  },
  {
    "objectID": "course.html#grading",
    "href": "course.html#grading",
    "title": "Course",
    "section": "Grading",
    "text": "Grading\n\n10%: Scribe lecture notes\n30%: Four assignments\n15%: Midterm mini project\n20%: In-class midterm\n25%: Capstone project",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Course</span>"
    ]
  },
  {
    "objectID": "course.html#policies",
    "href": "course.html#policies",
    "title": "Course",
    "section": "Policies",
    "text": "Policies\n\nLate Submissions:  All deadlines are due at on the date and time indicated on the course page. The penalties for late submission are as follows:\n\nless than a day : 25% penalty\nmore than a day, less than two days: 50% penalty\n75% penalty otherwise.\n\nMake-up Exam/Submission Policy: As per institute policy\nCitation Policy for Papers: Always mention the source, give full attribution and credits to citations, and as per institute policy\nAcademic Dishonesty/Plagiarism: As per institute policy\nAccommodation of Divyangs: As per institute policy\n\nSoma S Dhavala\nCourse Instructor",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Course</span>"
    ]
  },
  {
    "objectID": "course.html#resources",
    "href": "course.html#resources",
    "title": "Course",
    "section": "Resources",
    "text": "Resources\n\n\n[1] A.\nBurkov, ML engineering. LeanPub, 2019. Available: https://www.mlebook.com/wiki/doku.php\n\n\n[2] V.\nTuulos, Effective data science infrastructure. Manning, 2023.\nAvailable: https://www.manning.com/books/effective-data-science-infrastructure\n\n\n[3] C.\nHuyen, ML system design. O’Rielly, 2023. Available: https://www.oreilly.com/library/view/designing-machine-learning/9781098107956/\n\n\n[4] C.\nHuyen, “CS329S @ stanford - lecture 1: ML systems in\nproduction,” [Online]. Available: https://docs.google.com/document/d/1C3dlLmFdYHJmACVkz99lSTUPF4XQbWb_Ah7mPE12Igo/edit#heading=h.a8w2b79yy875\n\n\n[5] G.\nMohandas, “MLOps course.” [Online]. Available: https://github.com/GokuMohandas/mlops-course\n\n\n[6] C.\nHuyen, “CS329S: ML systems design.” [Online]. Available: https://stanford-cs329s.github.io/",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Course</span>"
    ]
  },
  {
    "objectID": "course.html#additional-resources",
    "href": "course.html#additional-resources",
    "title": "Course",
    "section": "Additional Resources",
    "text": "Additional Resources\n\n[Book] Writing for clarity",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Course</span>"
    ]
  },
  {
    "objectID": "course.html#discussions",
    "href": "course.html#discussions",
    "title": "Course",
    "section": "Discussions",
    "text": "Discussions\nJoin this discord channel. Use - as id (no anonymous handles, please).",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Course</span>"
    ]
  },
  {
    "objectID": "lectures/W01-L01.html",
    "href": "lectures/W01-L01.html",
    "title": "01-Introduction",
    "section": "",
    "text": "Notes: 1. We will go over this deck from Chip Huyen’s CS329S: ML System Design Fall’22 @ Stanford 2. Few more",
    "crumbs": [
      "Lectures",
      "01-Introduction"
    ]
  },
  {
    "objectID": "lectures/W01-L02.html",
    "href": "lectures/W01-L02.html",
    "title": "02-Data-Engineering",
    "section": "",
    "text": "Notes: 1. We will go over this deck from Chip Huyen’s CS329S: ML System Design Fall’22 @ Stanford 2. Few more",
    "crumbs": [
      "Lectures",
      "02-Data-Engineering"
    ]
  },
  {
    "objectID": "lectures/w01-l01.html",
    "href": "lectures/w01-l01.html",
    "title": "01:Grounding MLOps",
    "section": "",
    "text": "Materials:",
    "crumbs": [
      "Lectures",
      "01:Grounding MLOps"
    ]
  },
  {
    "objectID": "lectures/w02-l01.html",
    "href": "lectures/w02-l01.html",
    "title": "02:Data Engineering",
    "section": "",
    "text": "tbd",
    "crumbs": [
      "Lectures",
      "02:Data Engineering"
    ]
  },
  {
    "objectID": "lectures/w01-l01.html#concepts",
    "href": "lectures/w01-l01.html#concepts",
    "title": "01:Grounding MLOps",
    "section": "",
    "text": "We will go over this deck from Chip Huyen’s CS329S: ML System Design Fall’22 @ Stanford\nSoftware 1.0 vs Software 2.0. See this Figure\nML Model is a DAG.\nML Life Cycle CRISP-ML9(Q): blog, paper",
    "crumbs": [
      "Lectures",
      "01:Grounding MLOps"
    ]
  },
  {
    "objectID": "lectures/w01-l01.html#notes",
    "href": "lectures/w01-l01.html#notes",
    "title": "01:Grounding MLOps",
    "section": "",
    "text": "Pre-read:\n\nRefresh ML foundations.\nRead “The 100 page ML book” by Andiry Burkov. Chapters accessible for free here\n\n\n\nMaterials\n\nWe will go over this deck from Chip Huyen’s CS329S: ML System Design Fall’22 @ Stanford\nSoftware 1.0 vs Software 2.0. See this Figure\nML Model is a DAG\nML Life Cycle CRISP-ML9(Q): blog, paper",
    "crumbs": [
      "Lectures",
      "01:Grounding MLOps"
    ]
  },
  {
    "objectID": "assignments.html",
    "href": "assignments.html",
    "title": "Homeworks",
    "section": "",
    "text": "HW-01",
    "crumbs": [
      "Homeworks"
    ]
  },
  {
    "objectID": "assignments.html#hw-01",
    "href": "assignments.html#hw-01",
    "title": "Homeworks",
    "section": "",
    "text": "Read the paper Towards CRISP-ML(Q): A Machine Learning Process Model with QA Methedology here\nRead about Project Canvas here\nRead this lecture notes from CS329S’F22\nPick your favorite problem. Complete the information required in the Project Canvas.\nSubmit your response in this Google Form tbd\nDue by 11.59PM IST, 13th August, 2024.",
    "crumbs": [
      "Homeworks"
    ]
  },
  {
    "objectID": "assignments.html#hw-02",
    "href": "assignments.html#hw-02",
    "title": "Homeworks",
    "section": "HW-02",
    "text": "HW-02",
    "crumbs": [
      "Homeworks"
    ]
  },
  {
    "objectID": "lectures/w01-l01.html#materials",
    "href": "lectures/w01-l01.html#materials",
    "title": "01:Grounding MLOps",
    "section": "",
    "text": "Pre-read:\n\nRefresh ML foundations.\nRead “The 100 page ML book” by Andiry Burkov. Chapters accessible for free here\n\n\n\nIn-Class\n\nWe will go over this deck from Chip Huyen’s CS329S: ML System Design Fall’22 @ Stanford\nSoftware 1.0 vs Software 2.0. See this Figure\nML Model is a DAG\nML Life Cycle CRISP-ML9(Q): blog, paper",
    "crumbs": [
      "Lectures",
      "01:Grounding MLOps"
    ]
  },
  {
    "objectID": "lectures/w01-l01.html#scribed",
    "href": "lectures/w01-l01.html#scribed",
    "title": "01:Grounding MLOps",
    "section": "Scribed:\n",
    "text": "Scribed:",
    "crumbs": [
      "Lectures",
      "01:Grounding MLOps"
    ]
  },
  {
    "objectID": "homeworks.html",
    "href": "homeworks.html",
    "title": "Homeworks",
    "section": "",
    "text": "HW-01",
    "crumbs": [
      "Homeworks"
    ]
  },
  {
    "objectID": "homeworks.html#hw-01",
    "href": "homeworks.html#hw-01",
    "title": "Homeworks",
    "section": "",
    "text": "Read the paper Towards CRISP-ML(Q): A Machine Learning Process Model with QA Methedology here\nRead about Project Canvas here\nRead this lecture notes from CS329S’F22\nPick your favorite problem. Complete the information required in the Project Canvas.\nSubmit your response in this Google Form tbd\nDue by 11.59PM IST, 13th August, 2024.",
    "crumbs": [
      "Homeworks"
    ]
  }
]